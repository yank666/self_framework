/****************************************************************************
 *   Generated by ACUITY 5.16.3
 *   Match ovxlib 1.1.26
 *
 *   Neural Network appliction pre-process source file
 ****************************************************************************/
/*-------------------------------------------
                Includes
-------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "vsi_nn_pub.h"
#include "vnn_global.h"
#include "vnn_pre_process.h"

#define _BASETSD_H

/*-------------------------------------------
                  Variable definitions
-------------------------------------------*/

/*{graph_input_idx, preprocess}*/
const static vsi_nn_preprocess_map_element_t *preprocess_map = NULL;

/*-------------------------------------------
                  Functions
-------------------------------------------*/
#define INPUT_META_NUM 1
#define CHANNEL_NUM 3
#define MEAN_NORM_NUM 4
static vnn_input_meta_t input_meta_tab[INPUT_META_NUM];
static uint32_t channel_array[CHANNEL_NUM];
static float mean_norm_array[MEAN_NORM_NUM];

static void _load_input_meta() {
  uint32_t i;
  for (i = 0; i < INPUT_META_NUM; i++) {
    memset(&input_meta_tab[i].image.preprocess, VNN_PREPRO_NONE,
           sizeof(int32_t) * VNN_PREPRO_NUM);

    input_meta_tab[i].image.preprocess[0] = VNN_PREPRO_REORDER;
    input_meta_tab[i].image.preprocess[1] = VNN_PREPRO_MEAN;
    input_meta_tab[i].image.preprocess[2] = VNN_PREPRO_SCALE;
    input_meta_tab[i].image.reorder[0] = channel_array[0];
    input_meta_tab[i].image.reorder[1] = channel_array[1];
    input_meta_tab[i].image.reorder[2] = channel_array[2];
    input_meta_tab[i].image.mean[0] = mean_norm_array[0];
    input_meta_tab[i].image.mean[1] = mean_norm_array[1];
    input_meta_tab[i].image.mean[2] = mean_norm_array[2];
    input_meta_tab[i].image.scale = mean_norm_array[3];
  }
  /* lid: input_0_0 */
}

static uint8_t *_float32_to_dtype(float *fdata, vsi_nn_tensor_t *tensor,
                                  uint8_t *dtype_data) {
  vsi_status status;
  uint8_t *data;
  uint32_t sz, i, stride;
  float scale;
  int32_t zero_point;
  float fl;

  if (tensor->attr.dtype.vx_type == VSI_NN_TYPE_UINT8) {
    scale = tensor->attr.dtype.scale;
    zero_point = tensor->attr.dtype.zero_point;
  } else {
    fl = pow(2., tensor->attr.dtype.fl);
  }

  sz = vsi_nn_GetElementNum(tensor);
  stride = vsi_nn_TypeGetBytes(tensor->attr.dtype.vx_type);
  data = dtype_data;
  // data = (uint8_t *)malloc(stride * sz * sizeof(uint8_t));
  TEST_CHECK_PTR(data, final);
  memset(data, 0, stride * sz * sizeof(uint8_t));

  for (i = 0; i < sz; i++) {
    /*status = vsi_nn_Float32ToDtype(fdata[i], &data[stride * i],
    &tensor->attr.dtype); if(status != VSI_SUCCESS)
    {
        if(data)free(data);
        return NULL;
    }*/
    switch (tensor->attr.dtype.vx_type) {
      case VSI_NN_TYPE_UINT8:
        *(&data[stride * i]) = (uint8_t)(fdata[i] / scale + zero_point);
        break;
      case VSI_NN_TYPE_INT8:
        *(int8_t *)(&data[stride * i]) = (int8_t)(fdata[i] * fl);
        break;
      case VSI_NN_TYPE_INT16:
        *(int16_t *)(&data[stride * i]) = (int16_t)(fdata[i] * fl);
        break;
      case VSI_NN_TYPE_FLOAT32:
        *(float *)(&data[stride * i]) = fdata[i];
        break;
      default:
        break;
    }
  }

final:
  return data;
}

static float *_imageData_to_float32(uint8_t *bmpData, vsi_nn_tensor_t *tensor,
                                    float *input_data) {
  float *fdata;
  uint32_t sz, i;

  fdata = NULL;
  sz = vsi_nn_GetElementNum(tensor);
  fdata = input_data;
  // fdata = (float *)malloc(sz * sizeof(float));
  TEST_CHECK_PTR(fdata, final);
  memset(fdata, 0, sz * sizeof(float));

  for (i = 0; i < sz; i++) {
    fdata[i] = (float)bmpData[i];
  }

final:
  return fdata;
}

static void _prepare_imageprocess_params(
  vsi_nn_imageprocess_param *imageprocess, int32_t *crop_start,
  int32_t *crop_length, int32_t *resize_length) {
  float scale = input_meta_tab[0].image.scale;
  float *mean_value = input_meta_tab[0].image.mean;
  uint32_t *reorder = input_meta_tab[0].image.reorder;

  imageprocess->platform_type = VSI_NN_PLATFORM_CAFFE;
  imageprocess->crop.enable = TRUE;
  imageprocess->crop.dim_num = 4;
  imageprocess->crop.start = crop_start;
  imageprocess->crop.length = crop_length;

  if (mean_value[0] != 0 && mean_value[1] != 0 && mean_value[2] != 0) {
    imageprocess->mean.type = VSI_NN_IMAGEPROCESS_MEAN_CHANNEL;
    imageprocess->mean.mean_value_size = 3;
    imageprocess->mean.mean_value = mean_value;
  } else {
    imageprocess->mean.type = VSI_NN_IMAGEPROCESS_MEAN_NONE;
  }
  if (scale == 0.0) {
    imageprocess->mean.scale = 1.0f;
  } else {
    imageprocess->mean.scale = scale;
  }

  imageprocess->resize.type = VSI_NN_IMAGEPROCESS_RESIZE_BILINEAR;
  imageprocess->resize.dim_num = 2;
  imageprocess->resize.length = resize_length;
  imageprocess->reverse_channel = FALSE;
  if (reorder[0] == 0 && reorder[1] == 1 && reorder[2] == 2) {
    imageprocess->reverse_channel = vx_true_e;
  }
}

static void _data_scale(float *fdata, vnn_input_meta_t *meta,
                        vsi_nn_tensor_t *tensor) {
  uint32_t i, sz;
  float val, scale;

  sz = vsi_nn_GetElementNum(tensor);
  scale = meta->image.scale;
  if (0 != scale) {
    for (i = 0; i < sz; i++) {
      val = fdata[i] * scale;
      fdata[i] = val;
    }
  }
}

static void _data_mean(float *fdata, vnn_input_meta_t *meta,
                       vsi_nn_tensor_t *tensor) {
  uint32_t s0, s1, s2;
  uint32_t i, j, offset;
  float val, mean;

  s0 = tensor->attr.size[0];
  s1 = tensor->attr.size[1];
  s2 = tensor->attr.size[2];

  for (i = 0; i < s2; i++) {
    offset = s0 * s1 * i;
    mean = meta->image.mean[i];
    for (j = 0; j < s0 * s1; j++) {
      val = fdata[offset + j] - mean;
      fdata[offset + j] = val;
    }
  }
}

/*
    caffe: transpose + reorder
    tf: reorder
*/
static void _data_transform(float *fdata, vnn_input_meta_t *meta,
                            vsi_nn_tensor_t *tensor, float *transform_data) {
  uint32_t s0, s1, s2;
  uint32_t i, j, offset, sz, order;
  float *data;
  uint32_t *reorder;

  data = NULL;
  reorder = meta->image.reorder;
  s0 = tensor->attr.size[0];
  s1 = tensor->attr.size[1];
  s2 = tensor->attr.size[2];
  sz = vsi_nn_GetElementNum(tensor);
  data = transform_data;
  // data = (float *)malloc(sz * sizeof(float));
  // TEST_CHECK_PTR(data, final);
  if (data == NULL) {
    goto final;
  }
  memset(data, 0, sizeof(float) * sz);

  for (i = 0; i < s2; i++) {
    if (s2 > 1 && reorder[i] <= s2) {
      order = reorder[i];
    } else {
      order = i;
    }

    offset = s0 * s1 * i;
    for (j = 0; j < s0 * s1; j++) {
      data[j + offset] = fdata[j * s2 + order];
    }
  }

  memcpy(fdata, data, sz * sizeof(float));
final:
  // if(data)free(data);
  return;
}

vsi_status vnn_SetChannelandMean(uint32_t channel_format, float *mean,
                                 float *norm) {
  if (channel_format == 0) {
    channel_array[0] = 0;
    channel_array[1] = 1;
    channel_array[2] = 2;
  } else {
    channel_array[0] = 2;
    channel_array[1] = 1;
    channel_array[2] = 0;
  }
  mean_norm_array[0] = mean[0];
  mean_norm_array[1] = mean[1];
  mean_norm_array[2] = mean[2];
  mean_norm_array[3] = norm[0];
}

vsi_status vnn_PreProcessByPixels(vsi_nn_graph_t *graph, void *img_data,
                                  float *input_data, float *transform_data,
                                  uint8_t *dtype_data) {
  vsi_nn_tensor_t *tensor;
  vsi_status status = VSI_FAILURE;
  vnn_input_meta_t meta;
  float *fdata = NULL;
  uint8_t *data = NULL;
  char dumpInput[128];

  _load_input_meta();
  memset(&meta, 0, sizeof(vnn_input_meta_t));
  tensor = vsi_nn_GetTensor(graph, graph->input.tensors[0]);
  meta = input_meta_tab[0];

  fdata = _imageData_to_float32((uint8_t *)img_data, tensor, input_data);
  TEST_CHECK_PTR(fdata, final);

  for (int i = 0; i < _cnt_of_array(meta.image.preprocess); i++) {
    switch (meta.image.preprocess[i]) {
      case VNN_PREPRO_NONE:
        break;
      case VNN_PREPRO_REORDER:
        _data_transform(fdata, &meta, tensor, transform_data);
        break;
      case VNN_PREPRO_MEAN:
        _data_mean(fdata, &meta, tensor);
        break;
      case VNN_PREPRO_SCALE:
        _data_scale(fdata, &meta, tensor);
        break;
      default:
        break;
    }
  }

  data = _float32_to_dtype(fdata, tensor, dtype_data);
  TEST_CHECK_PTR(data, final);

  /* Copy the Pre-processed data to input tensor */
  status = vsi_nn_CopyDataToTensor(graph, tensor, data);
  // memcpy(input_buffer, data, input_buffer_size);
  // vsi_nn_FlushHandle(tensor);
  TEST_CHECK_STATUS(status, final);

  /* Save the image data to file */
  // snprintf(dumpInput, sizeof(dumpInput), "input_%d.dat", 0);
  // vsi_nn_SaveTensorToBinary(graph, tensor, dumpInput);

  status = VSI_SUCCESS;

final:
  /*if (fdata) {
      free(fdata);
  }
  if (data) {
      free(data);
  }*/
  return status;
}

const vsi_nn_preprocess_map_element_t *vnn_GetPrePorcessMap() {
  return preprocess_map;
}

uint32_t vnn_GetPrePorcessMapCount() {
  if (preprocess_map == NULL)
    return 0;
  else
    return sizeof(preprocess_map) / sizeof(vsi_nn_preprocess_map_element_t);
}
